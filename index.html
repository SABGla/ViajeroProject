<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>ViAjeRo ERC Advanced Grant Project</title> <meta name="author" content="Stephen Brewster"> <meta name="description" content="ViAjeRo is a 5 year ERC Advanced Grant exploring passenger use of extended, augmented, and virtual reality headsets. "> <meta name="keywords" content="ERC, VIAJERO, PASSENGERS, AUGMENTED REALITY, VIRTUAL REALITY, EXTENDED REALITY, MOTION SICKNESS"> <link rel="stylesheet" href="/ViajeroProject/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/ViajeroProject/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/ViajeroProject/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/ViajeroProject/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sabgla.github.io/ViajeroProject/"> </head> <body class="d-flex flex-column min-vh-100"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/ViajeroProject/">Home<span class="sr-only">(current)</span></a> </li> <li class="nav-item active"> <a class="nav-link" href="/ViajeroProject/news/">News</a> </li> <li class="nav-item "> <a class="nav-link" href="/ViajeroProject/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/ViajeroProject/contact/">Contact</a> </li> <li class="nav-item "> <a class="nav-link" href="/ViajeroProject/team/">Team</a> </li> <li class="nav-item "> <a class="nav-link" href="/ViajeroProject/photomod/">PhotoMod</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <main class="flex-fill"> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> ViAjeRo ERC Advanced Grant Project </h1> <p class="desc"></p> </header> <article> <div class="clearfix"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /ViajeroProject/assets/img/header-car-480.webp 480w, /ViajeroProject/assets/img/header-car-800.webp 800w, /ViajeroProject/assets/img/header-car-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/ViajeroProject/assets/img/header-car.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; if (!this.src.includes('retry=1')) { this.src = this.src + '?retry=1'; }"> </picture> </figure> </div> </div> <p>The aim of <em>ViAjeRo</em> (Traveller in Spanish) is to <strong>radically improve all passenger journeys by facilitating the use of immersive Virtual and Augmented Reality (together called XR) to support entertainment, work and collaboration when on the move</strong>.</p> <p>In Europe, people travel an average of 12,000km per year on private and public transport, in cars, buses, planes and trains. These journeys are often repetitive and wasted time. This total will rise with the arrival of fully autonomous cars, which free drivers to become passengers. The potential to recover this lost time is impeded by 3 significant challenges:</p> <ul> <li>Confined spaces: These limit interactivity, and force us to rely on small displays such as phones or seatback screens</li> <li>Social acceptability:We may share the space with others, inducing a pressure to conform, inhibiting tech-nology use</li> <li>Motion sickness: Many people get sick when they read or play games in vehicles. Once experienced, it can take hours for symptoms to resolve.</li> </ul> <p>VR/AR headsets could allow passengers to use their travel time in new, productive, exciting ways, but only if bold research is undertaken to overcome these fundamental challenges. ViAjeRo will use VR/AR to do adventurous multidisciplinary work, unlocking the untapped potential of passengers. They will be able to use large virtual displays for productivity; escape the physical confines of the vehicle and become immersed in virtual experiences; and communicate with distant others through new embodied forms of communication – all whilst travelling. Our vision requires ground-breaking contributions at the intersection of HCI, neuroscience and sensing to:</p> <ul> <li>Develop novel interaction techniques for confined, seated spaces</li> <li>Support safe, socially acceptable use of VR/AR, providing awareness of others and the travel en-vironment</li> <li>Overcome motion sickness through novel multimodal countermeasures and neurostimulation</li> <li>Tailor the virtual and physical passenger environment to support new, immersive experiences</li> </ul> <p>ViAjeRo started in 2019 and finished in 2025, and you can explore our project outputs on this website.</p> <p>The Viajero project is an ERC Advanced Grant (101201656) to Professor Stephen Brewster, in the School of Computing Science at the University of Glasgow.</p> <hr> </div> <h2><a href="/ViajeroProject/news/" style="color: inherit;">News</a></h2> <div class="news"> <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"> <form class="example" id="news-search-form"> <input type="text" id="news-search-input" placeholder="Search news..."> <button type="submit"><i class="fa fa-search"></i></button> </form> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr class="news-entry" data-news=" apr 2, 2025 chi 25 – the spin doctor: rotational and translational gain in passive vr scenarios following up last years ludicrous paper, we are delighted to have another full paper accepted to acm chi 2025 in yokohama, on the perception of rotational and translational gain in vr in both a motorised simulator chair and moving car on real roads [1]. across two studies we measured the barely perceivable level of rotational gain as well as the maximum comfortable level when being rotated in a yawvr yaw2 simulator chair – examing the effects of speed, turn angle, task and motion congruence. we then applied what we learned to a third study where car passengers experienced an ‘unbounded’ vr spaceship game where the real car turns and speed were amplified by 3-10x and we measured perception of any mismatch. we found that the barely perceivable gain level was ~4x the real rotation, the maximum comfortable gain was a massive 14-17x real rotation, and participants are largely unable to tell when the real and virtual motion are in opposite directions. the results and our guidelines show how passive motion scenarios – such as simulators, gaming chairs, rollercoasters and vehicular xr – can greatly amplify the perceived amount of virtual motion, decoupling physical and virtual movement to provide a wider range of experiences. references [1] g. wilson, k. m. t. pohlmann, d. al baiaty suarez, m. mcgill, and s. a. brewster, “the spin doctor: leveraging insensitivity to passive rotational &amp; translational gain for unbounded motion-based vr experiences,” in proceedings of the 2025 chi conference on human factors in computing systems, new york, ny, usa, 2025. following up last years ludicrous paper, we are delighted to have another full paper accepted to acm chi 2025 in yokohama, on the perception of rotational and translational gain in vr in both a motorised simulator chair and moving car on real roads [1]. across two studies we measured the barely perceivable level of rotational gain as well as the maximum comfortable level when being rotated in a yawvr yaw2 simulator chair – examing the effects of speed, turn angle, task and motion congruence. we then applied what we learned to a third study where car passengers experienced an ‘unbounded’ vr spaceship game where the real car turns and speed were amplified by 3-10x and we measured perception of any mismatch. we found that the barely perceivable gain level was ~4x the real rotation, the maximum comfortable gain was a massive 14-17x real rotation, and participants are largely unable to tell when the real and virtual motion are in opposite directions. the results and our guidelines show how passive motion scenarios – such as simulators, gaming chairs, rollercoasters and vehicular xr – can greatly amplify the perceived amount of virtual motion, decoupling physical and virtual movement to provide a wider range of experiences. references [1] g. wilson, k. m. t. pohlmann, d. al baiaty suarez, m. mcgill, and s. a. brewster, “the spin doctor: leveraging insensitivity to passive rotational &amp; translational gain for unbounded motion-based vr experiences,” in proceedings of the 2025 chi conference on human factors in computing systems, new york, ny, usa, 2025. "> <th scope="row" class="news-date" style="width: 20%">Apr 2, 2025</th> <td> <p class="news-title"> <a href="/ViajeroProject/news/announcement_1/"><b>CHI 25 – The Spin Doctor: Rotational and Translational Gain in Passive VR Scenarios</b></a> </p> <p>Following up last years Ludicrous paper, we are delighted to have another full paper accepted to ACM CHI 2025 in Yokohama, on the perception of rotational and translational gain in VR in both a motorised simulator chair and moving car on real roads [1]. <br> <br> Across two studies we measured the barely perceivable level of rotational gain as well as the maximum comfortable level when being rotated in a YawVR Yaw2 simulator chair – examing the effects of Speed, Turn Angle, Task and Motion Congruence. We then applied what we learned to a third study where car passengers experienced an ‘unbounded’ VR spaceship game where the real car turns and speed were amplified by 3-10x and we measured perception of any mismatch. <br> <br> We found that the barely perceivable gain level was ~4x the real rotation, the maximum comfortable gain was a massive 14-17x real rotation, and participants are largely unable to tell when the real and virtual motion are in opposite directions. The results and our guidelines show how passive motion scenarios – such as simulators, gaming chairs, rollercoasters and vehicular XR – can greatly amplify the perceived amount of virtual motion, decoupling physical and virtual movement to provide a wider range of experiences. <br> <br> <b>References</b> <br> <a href="https://link.springer.com/article/10.1007/s10055-019-00420-x" target="_blank" rel="external nofollow noopener"> [1] G. Wilson, K. M. T. Pohlmann, D. Al Baiaty Suarez, M. Mcgill, and S. A. Brewster, “The spin doctor: leveraging insensitivity to passive rotational &amp; translational gain for unbounded motion-based VR experiences,” in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, New York, NY, USA, 2025.</a></p> </td> </tr> <tr class="news-entry" data-news=" mar 25, 2024 chi 2024- from slow-mo to ludicrous speed we are very happy to have a full paper accepted to acm chi 2024 in hawai’i, on using translational gain and attenuation in vr to comfortably manipulate the perceived speed of a moving car [1]. a pre-print is available here. using our passengxr motion platform, we conveyed the car’s movement to a vr headset and either increased (1.5x-9.5x) or decreased (0.66x to 0.14x) the virtual speed 1) through a cityscape during a reading/productivity task and 2) through a space station trench during a spaceship shooting game. we investigated how well passengers can detect the manipulation in speed, how it affected motion sickness, and whether it altered the perceived speed or distance of car journey. references [1] k. m. t. pohlmann, g. wilson, g. li, m. mcgill, and s. a. brewster, “from slow-mo to ludicrous speed: comfortably manipulating the perception of linear in-car vr motion through vehicular translational gain and attenuation,” in proceedings of the 2024 chi conference on human factors in computing systems, new york, ny, usa, 2024. we are very happy to have a full paper accepted to acm chi 2024 in hawai’i, on using translational gain and attenuation in vr to comfortably manipulate the perceived speed of a moving car [1]. a pre-print is available here. using our passengxr motion platform, we conveyed the car’s movement to a vr headset and either increased (1.5x-9.5x) or decreased (0.66x to 0.14x) the virtual speed 1) through a cityscape during a reading/productivity task and 2) through a space station trench during a spaceship shooting game. we investigated how well passengers can detect the manipulation in speed, how it affected motion sickness, and whether it altered the perceived speed or distance of car journey. references [1] k. m. t. pohlmann, g. wilson, g. li, m. mcgill, and s. a. brewster, “from slow-mo to ludicrous speed: comfortably manipulating the perception of linear in-car vr motion through vehicular translational gain and attenuation,” in proceedings of the 2024 chi conference on human factors in computing systems, new york, ny, usa, 2024. "> <th scope="row" class="news-date" style="width: 20%">Mar 25, 2024</th> <td> <p class="news-title"> <a href="/ViajeroProject/news/announcement_2/"><b>CHI 2024- From Slow-Mo to Ludicrous Speed</b></a> </p> <p>We are very happy to have a full paper accepted to ACM CHI 2024 in Hawai’i, on using translational gain and attenuation in VR to comfortably manipulate the perceived speed of a moving car [1]. A pre-print is available here. <br> <br> Using our PassengXR motion platform, we conveyed the car’s movement to a VR headset and either increased (1.5x-9.5x) or decreased (0.66x to 0.14x) the virtual speed 1) through a cityscape during a reading/productivity task and 2) through a space station trench during a spaceship shooting game. We investigated how well passengers can detect the manipulation in speed, how it affected motion sickness, and whether it altered the perceived speed or distance of car journey. <br> <br> <b>References</b> <br> <a href="https://eprints.gla.ac.uk/322639%20" target="_blank" rel="external nofollow noopener"> [1] K. M. T. Pohlmann, G. Wilson, G. Li, M. Mcgill, and S. A. Brewster, “From slow-mo to ludicrous speed: comfortably manipulating the perception of linear in-car vr motion through vehicular translational gain and attenuation,” in Proceedings of the 2024 chi conference on human factors in computing systems, New York, NY, USA, 2024.</a></p> </td> </tr> <tr class="news-entry" data-news=" nov 18, 2022 passengxr motion platform &amp; uist paper led by mark mcgill, the viajero project has produced an open-source and off-the-shelf hardware and software motion platform for creating vehicular xr experiences: passengxr. published at acm uist 2022 [1], the motion platform uses esp32 arduino sensors to detect the orientation (imu), velocity (obd-ii) and location (gnss) of the vehicle and wirelessly broadcast these to a unity software platform running on standalone xr headsets. this allows practitioners to create passenger xr experiences that make use of, or counteract, the motion of the vehicle. passengxr supports multiple concurrent users in both individual and shared experiences and includes a number of ways to correct the alignment of vehicle and headset imus, which are inherently prone to drifting when in-motion. all code for the motion platform will be made available through github, and more information can be found on the motion platform page and in the uist paper [1]. references [1] m. mcgill, g. wilson, d. medeiros, and s. brewster, “passengxr: a low cost platform for any-car, multi-user, motion-based passenger xr experiences,” in uist ’22: proceedings of the 35th annual acm symposium on user interface software and technology, , 2022. led by mark mcgill, the viajero project has produced an open-source and off-the-shelf hardware and software motion platform for creating vehicular xr experiences: passengxr. published at acm uist 2022 [1], the motion platform uses esp32 arduino sensors to detect the orientation (imu), velocity (obd-ii) and location (gnss) of the vehicle and wirelessly broadcast these to a unity software platform running on standalone xr headsets. this allows practitioners to create passenger xr experiences that make use of, or counteract, the motion of the vehicle. passengxr supports multiple concurrent users in both individual and shared experiences and includes a number of ways to correct the alignment of vehicle and headset imus, which are inherently prone to drifting when in-motion. all code for the motion platform will be made available through github, and more information can be found on the motion platform page and in the uist paper [1]. references [1] m. mcgill, g. wilson, d. medeiros, and s. brewster, “passengxr: a low cost platform for any-car, multi-user, motion-based passenger xr experiences,” in uist ’22: proceedings of the 35th annual acm symposium on user interface software and technology, , 2022. "> <th scope="row" class="news-date" style="width: 20%">Nov 18, 2022</th> <td> <p class="news-title"> <a href="/ViajeroProject/news/announcement_3/"><b>PassengXR Motion Platform &amp; UIST Paper</b></a> </p> <p>Led by Mark McGill, the Viajero project has produced an open-source and off-the-shelf hardware and software motion platform for creating vehicular XR experiences: PassengXR. <br> <br> Published at ACM UIST 2022 [1], the motion platform uses ESP32 Arduino sensors to detect the orientation (IMU), velocity (OBD-II) and location (GNSS) of the vehicle and wirelessly broadcast these to a Unity software platform running on standalone XR headsets. This allows practitioners to create passenger XR experiences that make use of, or counteract, the motion of the vehicle. <br> <br> PassengXR supports multiple concurrent users in both individual and shared experiences and includes a number of ways to correct the alignment of vehicle and headset IMUs, which are inherently prone to drifting when in-motion. All code for the motion platform will be made available through GitHub, and more information can be found on the Motion Platform page and in the UIST paper [1]. <br> <br> <b>References</b> <br> <a href="https://dl.acm.org/doi/10.1145/3526113.3545657" target="_blank" rel="external nofollow noopener"> [1] M. McGill, G. Wilson, D. Medeiros, and S. Brewster, “Passengxr: a low cost platform for any-car, multi-user, motion-based passenger xr experiences,” in Uist ’22: proceedings of the 35th annual acm symposium on user interface software and technology, , 2022.</a></p> </td> </tr> <tr class="news-entry" data-news=" oct 27, 2020 papers! prototypes! year 1 of viajero… it has not been an easy first year for viajero – the world has been turned upside down due to the covid-19 pandemic, and some of the fantastic research we wanted to pursue in cars and planes has had to be postponed. however, despite these setbacks, we have been making exciting progress towards some of viajero’s key aims! new people have joined the project, with daniel pires de sá medeiros joining as an ra looking at passenger interaction techniques. on the papers front, we’ve published on the key challenges in passenger mr [1], workspaces suited to confined spaces [2] (see below, presented at acm uist), the feasibility of neurostimulation [3, 4], ethical challenges in mixed reality [5] and auditory mixed reality [6, 7]. we’ve given talks about the project to the likes of the waterkant festival, audi, and bbc r&amp;d, and seen great interest in the concept of passenger mixed reality. development wise, here’s a sneak peek of our in-car platform being tested in glasgow, complete with accurate position and orientation tracking of a vehicle… on the neurostimulation side, gang li and frank pollick have been building the platform needed to explore the physiological signals that might indicate the onset of motion sickness… and regarding lab work, we recently took receipt of a rotovr chair, which will enable us to explore motion sickness from the safety of a lab environment! we hope that in the coming year society can start to get back to normal and beat covid-19, and we’ll be pursuing more passenger mr research so that, when travel resumes, people can make the most of their travel time! references [1] m. mcgill, j. williamson, a. ng, f. pollick, and s. brewster, “challenges in passenger use of mixed reality headsets in cars and other transportation,” virtual reality, 2019. [2] m. mcgill, a. kehoe, e. freeman, and s. brewster, “expanding the bounds of seated virtual workspaces,” acm trans. comput.-hum. interact., vol. 27, iss. 3, 2020. [3] g. li, m. mcgill, s. brewster, and f. pollick, “a review of electrostimulation-based cybersickness mitigations,” in 2020 ieee international conference on artificial intelligence and virtual reality (aivr), 2020. [4] honorable mention award g. li, m. varela, a. francisco habib, q. zhang, m. mcgill, s. brewster, and f. pollick, “exploring the feasibility of mitigating vr-hmd-induced cybersickness using cathodal transcranial direct current stimulation,” in 2020 ieee international conference on artificial intelligence and virtual reality (aivr), 2020. [5] j. gugenheimer, m. mcgill, s. huron, c. mai, j. williamson, and m. nebeling, “exploring potentially abusive ethical, social and political implications of mixed reality research in hci,” in extended abstracts of the 2020 chi conference on human factors in computing systems, new york, ny, usa, 2020, p. 1–8. [6] m. mcgill, s. brewster, d. mcgookin, and g. wilson, “acoustic transparency and the changing soundscape of auditory mixed reality,” in proceedings of the 2020 chi conference on human factors in computing systems, new york, ny, usa, 2020, p. 1–16. [7] m. mcgill, f. mathis, m. khamis, and j. williamson, “augmenting tv viewing using acoustically transparent auditory headsets,” in acm international conference on interactive media experiences, new york, ny, usa, 2020, p. 34–44. it has not been an easy first year for viajero – the world has been turned upside down due to the covid-19 pandemic, and some of the fantastic research we wanted to pursue in cars and planes has had to be postponed. however, despite these setbacks, we have been making exciting progress towards some of viajero’s key aims! new people have joined the project, with daniel pires de sá medeiros joining as an ra looking at passenger interaction techniques. on the papers front, we’ve published on the key challenges in passenger mr [1], workspaces suited to confined spaces [2] (see below, presented at acm uist), the feasibility of neurostimulation [3, 4], ethical challenges in mixed reality [5] and auditory mixed reality [6, 7]. we’ve given talks about the project to the likes of the waterkant festival, audi, and bbc r&amp;d, and seen great interest in the concept of passenger mixed reality. development wise, here’s a sneak peek of our in-car platform being tested in glasgow, complete with accurate position and orientation tracking of a vehicle… on the neurostimulation side, gang li and frank pollick have been building the platform needed to explore the physiological signals that might indicate the onset of motion sickness… and regarding lab work, we recently took receipt of a rotovr chair, which will enable us to explore motion sickness from the safety of a lab environment! we hope that in the coming year society can start to get back to normal and beat covid-19, and we’ll be pursuing more passenger mr research so that, when travel resumes, people can make the most of their travel time! references [1] m. mcgill, j. williamson, a. ng, f. pollick, and s. brewster, “challenges in passenger use of mixed reality headsets in cars and other transportation,” virtual reality, 2019. [2] m. mcgill, a. kehoe, e. freeman, and s. brewster, “expanding the bounds of seated virtual workspaces,” acm trans. comput.-hum. interact., vol. 27, iss. 3, 2020. [3] g. li, m. mcgill, s. brewster, and f. pollick, “a review of electrostimulation-based cybersickness mitigations,” in 2020 ieee international conference on artificial intelligence and virtual reality (aivr), 2020. [4] honorable mention award g. li, m. varela, a. francisco habib, q. zhang, m. mcgill, s. brewster, and f. pollick, “exploring the feasibility of mitigating vr-hmd-induced cybersickness using cathodal transcranial direct current stimulation,” in 2020 ieee international conference on artificial intelligence and virtual reality (aivr), 2020. [5] j. gugenheimer, m. mcgill, s. huron, c. mai, j. williamson, and m. nebeling, “exploring potentially abusive ethical, social and political implications of mixed reality research in hci,” in extended abstracts of the 2020 chi conference on human factors in computing systems, new york, ny, usa, 2020, p. 1–8. [6] m. mcgill, s. brewster, d. mcgookin, and g. wilson, “acoustic transparency and the changing soundscape of auditory mixed reality,” in proceedings of the 2020 chi conference on human factors in computing systems, new york, ny, usa, 2020, p. 1–16. [7] m. mcgill, f. mathis, m. khamis, and j. williamson, “augmenting tv viewing using acoustically transparent auditory headsets,” in acm international conference on interactive media experiences, new york, ny, usa, 2020, p. 34–44. "> <th scope="row" class="news-date" style="width: 20%">Oct 27, 2020</th> <td> <p class="news-title"> <a href="/ViajeroProject/news/announcement_4/"><b>Papers! Prototypes! Year 1 of ViAjeRo…</b></a> </p> <p>It has not been an easy first year for ViAjero – the world has been turned upside down due to the Covid-19 pandemic, and some of the fantastic research we wanted to pursue in cars and planes has had to be postponed. However, despite these setbacks, we have been making exciting progress towards some of ViAjeRo’s key aims! New people have joined the project, with Daniel Pires de Sá Medeiros joining as an RA looking at passenger interaction techniques. On the papers front, we’ve published on the key challenges in passenger MR [1], workspaces suited to confined spaces [2] (see below, presented at ACM UIST), the feasibility of neurostimulation [3, 4], ethical challenges in mixed reality [5] and auditory mixed reality [6, 7]. <br> <br> We’ve given talks about the project to the likes of the Waterkant festival, Audi, and BBC R&amp;D, and seen great interest in the concept of passenger mixed reality. Development wise, here’s a sneak peek of our in-car platform being tested in Glasgow, complete with accurate position and orientation tracking of a vehicle… <br> <br> On the neurostimulation side, Gang Li and Frank Pollick have been building the platform needed to explore the physiological signals that might indicate the onset of motion sickness… <br> And regarding lab work, we recently took receipt of a RotoVR chair, which will enable us to explore motion sickness from the safety of a lab environment! <br> <br> We hope that in the coming year society can start to get back to normal and beat Covid-19, and we’ll be pursuing more passenger MR research so that, when travel resumes, people can make the most of their travel time! <br> <br> <b>References</b> <br> <a href="https://dl.acm.org/doi/abs/10.1007/s10055-019-00420-x" target="_blank" rel="external nofollow noopener"> [1] M. McGill, J. Williamson, A. Ng, F. Pollick, and S. Brewster, “Challenges in passenger use of mixed reality headsets in cars and other transportation,” Virtual reality, 2019. <br> <br> </a><a href="https://research.euanfreeman.co.uk/papers/TOCHI_Workspaces.pdf" target="_blank" rel="external nofollow noopener"> [2] M. Mcgill, A. Kehoe, E. Freeman, and S. Brewster, “Expanding the bounds of seated virtual workspaces,” Acm trans. comput.-hum. interact., vol. 27, iss. 3, 2020. <br> <br> </a><a href="https://eprints.gla.ac.uk/224088/" target="_blank" rel="external nofollow noopener"> [3] G. Li, M. McGill, S. Brewster, and F. Pollick, “A review of electrostimulation-based cybersickness mitigations,” in 2020 ieee international conference on artificial intelligence and virtual reality (aivr), 2020. <br> <br> </a><a href="https://eprints.gla.ac.uk/224089/" target="_blank" rel="external nofollow noopener"> [4] Honorable Mention Award G. Li, M. Varela, A. Francisco Habib, Q. Zhang, M. McGill, S. Brewster, and F. Pollick, “Exploring the feasibility of mitigating vr-hmd-induced cybersickness using cathodal transcranial direct current stimulation,” in 2020 ieee international conference on artificial intelligence and virtual reality (aivr), 2020. <br> <br> </a><a href="https://eprints.gla.ac.uk/237478/1/237478.pdf" target="_blank" rel="external nofollow noopener"> [5] J. Gugenheimer, M. McGill, S. Huron, C. Mai, J. Williamson, and M. Nebeling, “Exploring potentially abusive ethical, social and political implications of mixed reality research in hci,” in Extended abstracts of the 2020 chi conference on human factors in computing systems, New York, NY, USA, 2020, p. 1–8. <br> <br> </a><a href="https://eprints.gla.ac.uk/208325/" target="_blank" rel="external nofollow noopener"> [6] M. McGill, S. Brewster, D. McGookin, and G. Wilson, “Acoustic transparency and the changing soundscape of auditory mixed reality,” in Proceedings of the 2020 chi conference on human factors in computing systems, New York, NY, USA, 2020, p. 1–16. <br> <br> </a><a href="https://eprints.gla.ac.uk/214043/" target="_blank" rel="external nofollow noopener"> [7] M. McGill, F. Mathis, M. Khamis, and J. Williamson, “Augmenting tv viewing using acoustically transparent auditory headsets,” in Acm international conference on interactive media experiences, New York, NY, USA, 2020, p. 34–44.</a></p> </td> </tr> <tr class="news-entry" data-news=" feb 27, 2020 chi 2020 – auditory mixed reality paper we’re excited to be going to chi 2020 soon, where we’ll be presenting a paper on auditory mixed reality [1] , which you can see as a preprint here. we’ll also be running a workshop on the ethics of mixed reality. references [1] m. mcgill, s. brewster, d. mcgookin, and g. wilson, “acoustic transparency and the changing soundscape of auditory mixed reality,” in proceedings of the 2020 chi conference on human factors in computing systems, new york, ny, usa, 2020, p. 1–16. we’re excited to be going to chi 2020 soon, where we’ll be presenting a paper on auditory mixed reality [1] , which you can see as a preprint here. we’ll also be running a workshop on the ethics of mixed reality. references [1] m. mcgill, s. brewster, d. mcgookin, and g. wilson, “acoustic transparency and the changing soundscape of auditory mixed reality,” in proceedings of the 2020 chi conference on human factors in computing systems, new york, ny, usa, 2020, p. 1–16. "> <th scope="row" class="news-date" style="width: 20%">Feb 27, 2020</th> <td> <p class="news-title"> <a href="/ViajeroProject/news/announcement_5/"><b>CHI 2020 – Auditory Mixed Reality Paper</b></a> </p> <p>We’re excited to be going to CHI 2020 soon, where we’ll be presenting a paper on Auditory Mixed Reality [1] , which you can see as a preprint here. We’ll also be running a workshop on the Ethics of Mixed Reality. <br> <br> <b>References</b> <br> <a href="https://dl.acm.org/doi/10.1145/3266037.3266104" target="_blank" rel="external nofollow noopener"> [1] M. McGill, S. Brewster, D. McGookin, and G. Wilson, “Acoustic transparency and the changing soundscape of auditory mixed reality,” in Proceedings of the 2020 chi conference on human factors in computing systems, New York, NY, USA, 2020, p. 1–16.</a></p> </td> </tr> </table> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("news-search-input");document.getElementById("news-search-form").addEventListener("submit",function(e){e.preventDefault()}),e.addEventListener("input",function(){const t=e.value.toLowerCase();document.querySelectorAll(".news-entry").forEach(function(e){e.getAttribute("data-news").includes(t)?e.style.display="":e.style.display="none"})})});</script> </article> </div> </div> </main> <footer class="bg-white text-black border-top"> <div class="container text-center"> <footer class="bg-white text-black"> <div classs="container text-center"> <img src="/ViajeroProject/assets/img/logos/footer_logos.png" alt="Funded by UKRI, selected by the ERC, hosted at the University of Glasgow" style="object-fit: contain; max-height:10vh;"><br> <br>© Copyright 2025 Stephen Brewster. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/ViajeroProject/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/ViajeroProject/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/ViajeroProject/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/ViajeroProject/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/ViajeroProject/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/ViajeroProject/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>